{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import dlinputs as dli\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import simplejson\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dlinputs import filters, gopen, improc, utils\n",
    "from matplotlib import cm\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from itertools import islice\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "import tensorcom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022.95552\n",
      "CPU times: user 0 ns, sys: 163 ms, total: 163 ms\n",
      "Wall time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "with open(\"./imagenet_train-0000.tar\", \"rb\") as stream:\n",
    "    while True:\n",
    "        data = stream.read(1000000)\n",
    "        if len(data)==0: break\n",
    "        total += len(data)\n",
    "print(total/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tar Decoding and Decompressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.936435\n",
      "CPU times: user 262 ms, sys: 20.3 ms, total: 283 ms\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "source = dli.gopen.open_source(\"./imagenet_train-0000.tar\", decode=False)\n",
    "for sample in islice(source, 0, 1000):\n",
    "    total += len(sample[\"jpg\"])\n",
    "print(total/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.936435\n",
      "CPU times: user 394 ms, sys: 19.6 ms, total: 414 ms\n",
      "Wall time: 412 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "source = dli.gopen.open_source(\"./imagenet_train-0000.tgz\", decode=False)\n",
    "for sample in islice(source, 0, 1000):\n",
    "    total += len(sample[\"jpg\"])\n",
    "print(total/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478969\n",
      "CPU times: user 8.17 s, sys: 305 ms, total: 8.48 s\n",
      "Wall time: 8.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "source = dli.gopen.open_source(\"./imagenet_train-0000.tgz\", decode=dli.utils.autodecoder(\"PIL\"))\n",
    "for sample in islice(source, 0, 1000):\n",
    "    total += sample[\"jpg\"].size[0]\n",
    "    images.append(sample[\"jpg\"].convert(\"RGB\"))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG Decoding with Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting decoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile decoder.py\n",
    "from PIL import Image\n",
    "import io\n",
    "def decode(sample):\n",
    "    sample[\"jpg\"] = Image.open(io.BytesIO(sample[\"jpg\"]))\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(16)\n",
    "from decoder import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4727094 10000\n",
      "CPU times: user 11.9 s, sys: 3.91 s, total: 15.8 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "source = dli.gopen.open_source(\"./imagenet_train-0000.tar\", decode=False)\n",
    "count = 0\n",
    "for sample in pool.imap_unordered(decode, islice(source, 0, 10000)):\n",
    "    total += sample[\"jpg\"].size[0]\n",
    "    count += 1\n",
    "print(total, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-Based JPEG Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 640, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import numpy as np\n",
    "import nvidia.dali.plugin.pytorch as dalipyt\n",
    "\n",
    "with open(\"space.jpg\", \"rb\") as stream:\n",
    "    space = stream.read()\n",
    "        \n",
    "class DecoderPipe(Pipeline):\n",
    "    def __init__(self, batch_size, num_threads, device_id, pipelined = False, async = False):\n",
    "        super(DecoderPipe, self).__init__(batch_size,\n",
    "                                         num_threads,\n",
    "                                         device_id,\n",
    "                                         exec_pipelined=pipelined,\n",
    "                                         exec_async=async)\n",
    "        self.input = ops.ExternalSource()\n",
    "        self.decode = ops.nvJPEGDecoder(device = \"mixed\", output_type = types.RGB)\n",
    "\n",
    "    def define_graph(self):\n",
    "        self.jpegs = self.input()\n",
    "        return self.decode(self.jpegs)\n",
    "\n",
    "pipe = DecoderPipe(1, 1, 0)\n",
    "pipe.build()\n",
    "\n",
    "def dali2torch(dali_tensor):\n",
    "    import torch\n",
    "    import ctypes\n",
    "    assert dali_tensor.dtype() == \"B\"\n",
    "    tensor = torch.zeros(dali_tensor.shape(), dtype=torch.uint8, device=\"cuda\")\n",
    "    assert dali_tensor.shape() == list(tensor.shape)\n",
    "    dali_tensor.copy_to_external(ctypes.c_void_p(tensor.data_ptr()))\n",
    "    return tensor\n",
    "\n",
    "def gpudecode(jpeg):\n",
    "    pipe.feed_input(pipe.jpegs, [jpeg])\n",
    "    dali_tensors = pipe.run()[0]\n",
    "    assert len(dali_tensors) == 1\n",
    "    image = dali2torch(dali_tensors.at(0))\n",
    "    return image\n",
    "    \n",
    "gpudecode(space).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-by-one Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405015\n",
      "CPU times: user 3.36 s, sys: 175 ms, total: 3.53 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "source = dli.gopen.open_source(\"./imagenet_train-0000.tgz\", decode=False)\n",
    "for sample in islice(source, 0, 1000):\n",
    "    image = gpudecode(sample[\"jpg\"])\n",
    "    total += image.size(0)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreaded Batch Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DecoderPipe(1000, 8, 0)\n",
    "pipe.build()\n",
    "dali_tensors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405015\n",
      "CPU times: user 2.63 s, sys: 704 ms, total: 3.34 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global dali_tensors\n",
    "source = dli.gopen.open_source(\"./imagenet_train-0000.tgz\", decode=False)\n",
    "jpegs = [sample[\"jpg\"] for sample in islice(source, 0, 1000)]\n",
    "pipe.feed_input(pipe.jpegs, jpegs)\n",
    "dali_tensors = pipe.run()[0]\n",
    "images = [dali2torch(dali_tensors.at(i)) for i in range(len(dali_tensors))]\n",
    "images = [a.cpu().numpy() for a in images]\n",
    "total = np.sum([a.shape[0] for a in images])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 943 ms, sys: 0 ns, total: 943 ms\n",
      "Wall time: 940 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "augment = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                              transforms.RandomHorizontalFlip()])\n",
    "for image in images:\n",
    "    augment(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 s, sys: 18 ms, total: 21.4 s\n",
      "Wall time: 8.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "channel_stats = dict(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**channel_stats)\n",
    "])\n",
    "for image in images:\n",
    "    augment(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "CPU times: user 1.65 s, sys: 67.7 ms, total: 1.72 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "augment = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                              transforms.RandomHorizontalFlip()])\n",
    "for image in images:\n",
    "    a = np.asarray(augment(image)).astype(np.float16)\n",
    "    arrays.append(a)\n",
    "print(len(arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "CPU times: user 57.7 ms, sys: 8.22 ms, total: 65.9 ms\n",
      "Wall time: 64.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "serve = tensorcom.Connection(\"zpub://127.0.0.1:7893\")\n",
    "for array in arrays:\n",
    "    serve.send([array, 0])\n",
    "serve.close()\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Sending with Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 224, 224, 3)\n",
      "CPU times: user 137 ms, sys: 0 ns, total: 137 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "serve = tensorcom.Connection(\"zpub://127.0.0.1:7895\")\n",
    "for batch in filters.batched(50)(dict(img=array) for array in arrays):\n",
    "    serve.send([batch[\"img\"], 0])\n",
    "serve.close()\n",
    "print(batch[\"img\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "|Step              | s/1000 |\n",
    "|------------------|--------|\n",
    "|tar decoding      |  0.270 |\n",
    "|tgz decoding      |  0.412 |\n",
    "|JPEG decoding     |  8.640 |\n",
    "|simple aug        |  0.920 |\n",
    "|complex aug       |  7.920 |\n",
    "|simple aug + conv |  1.760 |\n",
    "|batch + send      |  0.158 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
